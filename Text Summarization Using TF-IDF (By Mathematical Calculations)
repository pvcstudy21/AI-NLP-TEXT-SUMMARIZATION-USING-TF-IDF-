# import libraries

import math
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import sent_tokenize, word_tokenize
from nltk.stem import PorterStemmer

nltk.download('all')

# Sample document
document ="""
Swords, more than just blades of metal, are whispers of history etched in cold steel. 
From the bronze thrusting spears of ancient Egypt to the razor-sharp katanas of feudal Japan, each curve and bevel tells a tale. 
They were instruments of both war and nobility, wielded by knights in shining armor and samurai in quiet contemplation. 
Though their reign as primary weapons has passed, swords remain symbols of power, precision, and a legacy forged in battlefields and whispered legends. 
Their allure, sharp as ever, beckons us to imagine the clash of steel, the clang of honor, and the echoes of a bygone era when a sword was more than just a weapon, it was an extension of the soul.
"""

#document = "India boasts a rich and diverse history that spans thousands of years, characterized by a tapestry of civilizations, empires, and cultural achievements. The ancient Indus Valley Civilization, one of the world's earliest urban cultures, flourished around 3300â€“1300 BCE, showcasing advanced city planning and trade networks."

#document = "Optacloud enables companies to automate their cloud savings by using ML-powered optimization to maximize performance across APIs and microservices (CPaaS, generative AI apps, etc). Companies can reduce cloud costs, improve latency & minimize carbon footprint at 0 upfront cost. Optacloud is cloud agnostic (AWS, GCP, Azure, Alibaba, DigitalOcean, etc) and integrates in less than a minute, without any extra engineering effort."

# 1. Tokenize the sentences
sentences = sent_tokenize(document)
total_documents = len(sentences)
print(sentences)

# 2. Create the Frequency matrix of the words in each sentence.
def _create_frequency_matrix(sentences):
    frequency_matrix = {}
    stopWords = set(stopwords.words("english"))
    ps = PorterStemmer()

    for sent in sentences:
        freq_table = {}
        words = word_tokenize(sent)
        for word in words:
            word = word.lower()
            word = ps.stem(word)
            if word in stopWords:
                continue

            if word in freq_table:
                freq_table[word] += 1
            else:
                freq_table[word] = 1

        frequency_matrix[sent[:15]] = freq_table

    return frequency_matrix

freq_matrix = _create_frequency_matrix(sentences)
print(freq_matrix)

# 3. Calculate TermFrequency and generate a matrix
def _create_tf_matrix(freq_matrix):
    tf_matrix = {}

    for sent, f_table in freq_matrix.items():
        tf_table = {}

        count_words_in_sentence = len(f_table)
        for word, count in f_table.items():
            tf_table[word] = count / count_words_in_sentence

        tf_matrix[sent] = tf_table

    return tf_matrix

tf_matrix = _create_tf_matrix(freq_matrix)
print(tf_matrix)